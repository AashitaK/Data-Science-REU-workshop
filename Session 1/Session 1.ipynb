{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Hands-on Introduction to Data Manipulation using Pandas  \n",
    "\n",
    "### Meet the Instructor:\n",
    "Aashita Kesarwani  \n",
    "Current job: Scientific Computing Specialist at Harvey Mudd College  \n",
    "Background:  \n",
    "- PhD in Mathematics from Tulane University (Number Theory)\n",
    "- Undergraduate from IIT (Indian Institute of Technology) in Applied Mathematics   \n",
    "\n",
    "Other roles: \n",
    "- Visiting AI Researcher at [deepkapha.ai](https://www.linkedin.com/company/digitalis-kapha-b-v-/)\n",
    "- Technical Reviewer, Deep Learning for Natural Language Processing course by [Packt](https://www.packtpub.com/)\n",
    "- [Open source contributor](https://pypi.org/user/Aashita/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is machine learning?\n",
    "- Learning from data without being explicit programming.\n",
    "\n",
    "How to approach a problem? Broadly two parts:\n",
    "- Data exploration and feature engineering (Session 1)\n",
    "- Model building, tuning and testing (Session 2)\n",
    "\n",
    "\n",
    "We will explore the [Titanic dataset from Kaggle](https://www.kaggle.com/c/titanic).  \n",
    "Goal of the competition: To apply the tools of machine learning to predict which passengers survived the Titanic tragedy.\n",
    "    \n",
    "### Today's session\n",
    "Topics to be covered today:  \n",
    "- Pandas dataframes as the data structure for datasets\n",
    "- Converting csv files to dataframes \n",
    "- Slicing and indexing dataframes using conditionals as well as iloc and loc methods.\n",
    "- Statistical summary and exploration of dataframes\n",
    "- Detecting and filling missing values in the dataframes \n",
    "- Regular expressions for data extraction\n",
    "- Feature engineering such as creating new features \n",
    "- Basic plots\n",
    "- Basic operations such as dropping rows/columns, setting index, replacing values of a column using a dictionary, etc.\n",
    "- Split-apply-combine operations by grouping rows of a dataframe\n",
    "- Encoding categorical variables\n",
    "- Correlation among features (optional)\n",
    "- Merging dataframes (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the relevant python modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# The following two modules matplotlib and seaborn are for plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Comment this if seaborn is not installed\n",
    "%matplotlib inline\n",
    "\n",
    "# The module re is for regular expressions\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas: an excellent tool to work with datasets\n",
    "\n",
    "Dataframes: the central data structure of pandas library\n",
    "- Evolved out of tables\n",
    "- Most suitable for data manipulation tasks  \n",
    "\n",
    "Pandas is built on top of numpy. The crucial difference between numpy matrices and pandas Dataframes is that the columns in a Dataframe can be of different datatypes such as numerical, categorical, textual, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the [Titanic dataset from Kaggle](https://www.kaggle.com/c/titanic) stored in the `csv` file as a dataframe using [`read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'titanic/'\n",
    "df = pd.read_csv(path + 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out to be rather big dataset to display, we can comment the above cell by adding # in front of df and run it again to get rid of the output.\n",
    "\n",
    "Next, let's check the numbers of rows and columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the dataset consists of 891 rows and 15 columns.\n",
    "\n",
    "We use `head()` function to peek into the first 5 rows (or any number of rows by using `head(n)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Description for the columns](https://www.kaggle.com/c/titanic/data) is as follows.  \n",
    "\n",
    "|Variable|\tDefinition|\tKey|   \n",
    "|:---  |:--- |:---|\n",
    "|PassengerId| Passenger ID |\n",
    "|Survived| \tSurvival|\t0 = No, 1 = Yes |\n",
    "|Pclass\t|Ticket class|\t1 = 1st, 2 = 2nd, 3 = 3rd|\n",
    "|Sex\t|Sex|\t\n",
    "|Age\t|Age in years\t|\n",
    "|SibSp\t|# of siblings / spouses aboard the Titanic\t|\n",
    "|Parch\t|# of parents / children aboard the Titanic\t|\n",
    "|Ticket\t|Ticket number\t|\n",
    "|Fare\t|Passenger fare\t|\n",
    "|Cabin\t|Cabin number\t|\n",
    "|Embarked\t|Port of Embarkation\t|C = Cherbourg, Q = Queenstown, S = Southampton|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What are the features?\n",
    "\n",
    "The final goal is to design a model to predict whether a passenger survives or not, which of the above features seem like important predictors? How can you analyse the data in view of this objective?\n",
    "\n",
    "* What is feature engineering?\n",
    "    * Missing values\n",
    "    * Encoding categorial features\n",
    "    * Creating new features from the existing ones using tools such as regular expressions, split-apply-combine operations on rows, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Selecting rows and columns from the dataframe\n",
    "\n",
    "How do we select a column from the dataframe? Say, we want to select the *Name* column from the dataframe. \n",
    "\n",
    "Remember, we used square brackets for indexing lists, strings and numpy arrays in Python, for example `A[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Name'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we do not want all the rows in the output, we have used `head()` function at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we select multiple columns? Suppose we want to select the columns *Name, Sex* and *Age* from the dataframe. Hint: Use a list of columns inside the square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select rows by putting a certain condition on a column. Say, we want only those rows for which the gender is *'female'*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Sex\"] == \"female\"].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to retrieve only the female passengers traveling in the first class. \n",
    "Hint: Add another conditional `df['Pclass']==1` to the above code using & and make sure to wrap the two conditionals with parenthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the number of passengers using the shape method which gives us both the number of columns and the number of rows. Write the code to count the number of female passengers in the traveling in the first class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `loc` and `iloc` methods\n",
    "So far, we have seen how to retrieve either some select columns or certain rows based on conditionals. What if we want to slice off a portion of the dataframe with some specific rows and columns? We use `.loc[]` or `.iloc[]` methods for this purpose. \n",
    "* `.iloc[]` method is primarily integer position based and gets rows/columns at particular positions in the index (so it only takes integers). \n",
    "* `loc[]` method is label based and gets rows/columns with particular labels from the index.\n",
    "\n",
    "The `loc[]` method allows us to put conditions on rows and retrieve select columns simultaneously.\n",
    "\n",
    "For example, we want to get the name and the survival information for all the adults above 70 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Age']>70, ['Name', 'Survived']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code to retrieve the **name, age and survival** information for all the **female passengers traveling in the first class**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `iloc[]` method let us retrieve rows by passing sequence of indexes. For example, we can select the rows numbered 100th to 105th. The indexing works exactly like python lists and numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[100:106]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code to retrieve every 100th row from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions for the exercise session:\n",
    "- There are two exercise sessions (section 2 and 3) below, the estimated time for which is 25 minutes each.\n",
    "- The exercises involves new concepts not covered in the guided session. Please feel free to ask questions and take help from the instructor and/or TAs.\n",
    "- The hints are provided for the exercises below. The inbuilt functions to be used are provided with a clickable link to the user manual. \n",
    "- The exercise session is time-bound and you are encouraged to work in groups to speed things up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploring the dataset (25 min)\n",
    "\n",
    "Use [`describe`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) function for numerical features (columns) to get a brief overview of the statistics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same as above for qualitative (non-numerical) features. Hint: Use `include=['O']` parameter in the [`describe`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Use the built-in pandas function to count the number of surviving and non-surviving passengers. Hint: Use [`value_counts()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) on the column `df['Survived']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a pie chart of the same using `matplotlib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal') \n",
    "plt.pie(df['Survived'].value_counts(), labels=('Died', \"Survived\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a bar chart for the survival rate among male and female passengers using `seaborn`. Here is [Seaborn cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Python_Seaborn_Cheat_Sheet.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Sex', y = 'Survived', data = df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the survival rate among passengers in each ticket class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the survival rate among both genders within the three ticket classes as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', hue='Sex', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above chart, do you think that the gender affect the chance of survival for all the three ticket classes equally? Or does it seem like gender's effect is more pronounced for a certain ticket class passengers than others? We plot the  point estimates and confidence intervals for each sub-category to see it more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x='Sex', y='Survived', hue='Pclass', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the steeper slope for the second class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that gender and ticket class put together give more information about the survival chance than both of them separately. Please feel free to later explore other variables and combination of variables in depth in your own time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many children were on board? Hint: Use indexing on rows using conditional on the *Age* column and then the [`shape`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html) method to count the rows as seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many of the children on board survived? Hint: Add another conditional for the *Survived* column to the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the functions [`isnull()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html) and [`sum()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sum.html) on the dataframe to find out the number of missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting missing values is an important first step in Feature Engineering, that is preparing the features (independent variables) to use for building the machine learning models. The next step is to handle those missing values. Depending on the data, sometimes it is a good idea to drop the rows or columns that have some or a lot of missing values, but that also means discarding relevant information. Another way to handle missing values is to fill them with something appropriate. \n",
    "\n",
    "1. Discuss the pros and cons of dropping the rows and/or columns with missing values in general. Should you drop none, all or some of the columns for this particular dataset in view of building the predictive model? Same question for dropping the rows with missing values.\n",
    "3. If you consider filling the missing values, what are the possible options? Can you make use of other values in that column to fill the missing values? Can you make use of other values in that row as well as values in that column to fill the missing values \n",
    "4. Can the title in the name column be used for guessing a passengers' age based on the age values of other passengers with the same title?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the most common port of embarkment? Hint: Check the frequency (counts) of each value in the Embarked column using the built-in function [`value_counts()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) as seen above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw above, there are missing values in the column for *Embarked*. Fill them with the most commonly occuring value. Hint: Use [`fillna()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check whether the missing values for the *Embarked* column is indeed filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not, there are two options to fix this. One is to set `inplace` parameter in the `fillna()` function as `True` and another is to use assignment operator `=` as in `df = df.function()`. \n",
    "\n",
    "***Question***: Why is the `inplace` keyword False by default? This is true not just for `fillna()` but for most built-in functions in pandas. \n",
    "\n",
    "Answer: To facilitate method chaining or piping i.e. invoking multiple operations one after the other. For example, `df.isnull().sum()` used above. Chaining is more commonly used in pandas as compared to another programming style i.e. using nested function calls. Please read more [here](https://towardsdatascience.com/the-unreasonable-effectiveness-of-method-chaining-in-pandas-15c2109e3c69), if interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should remove the *Cabin* column from the DataFrame-- too many values are missing. Hint: Use [`drop()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html) with appropriate value for the `axis` keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check whether the column is indeed dropped. If not, modify the code above accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the age of the oldest person on board? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all the passenger information for the oldest person on board. Hint: Use [`loc[]`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html) method with [`idxmax()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.idxmax.html) for the Age column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Engineering: Creating a new column for the titles of the passengers (25 min)\n",
    "\n",
    "Now, we are going to create a new feature (column) for titles of the passengers. For that, let us first take at the passengers' names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:20, 'Name'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice one of the identifying characteristics of the titles above are that they end with a period. Regular expressions are very useful in the process of data extraction and we will use them using the python module `re` to extract the titles from the *Name* column. We will use regular expressions characters to construct a pattern and then use built-in function `findall` for pattern matching.\n",
    "\n",
    "Some useful regular expression characters:\n",
    "- `\\w`: pattern must contain a word character, such as letters.\n",
    "- `[ ]`: pattern must contain one of the characters inside the square brackets. If there is only one character inside the square brackets, for example `[.]`, then the pattern must contain it.\n",
    "\n",
    "Let's try this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(\"\\w\\w[.]\", 'Braund, Mr. Owen Harris')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! It returned a list instead of the string, so we use indexing to get the first element of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(\"\\w\\w[.]\", 'Braund, Mr. Owen Harris')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try it on another name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(\"\\w\\w[.]\", 'Heikkinen, Miss. Laina')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we want a pattern that automatically detects the length of the title and returns the entire title.\n",
    "\n",
    "For regular expressions, \\+ is added to a character/pattern to denote it is present one or more times. For example, `\\w+` is used to denote one or more word characters. Fill in the regular expression in the below cell that will detect a period preceeded by one or more word characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in below:\n",
    "re.findall(\"FILL IN HERE\", 'Heikkinen, Miss. Laina')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be `'Miss.'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: For pattern matching the titles using regular expressions:\n",
    "- First we make sure it contains a period by using `[.]`. \n",
    "- Secondly, the period must be preceeded by word characters (one or more), so we use `\\w+[.]`.\n",
    "\n",
    "Write a function `get_title` that takes a name, extracts the title from it and returns the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the function is working properly by running the following two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_title('Futrelle, Mrs. Jacques Heath (Lily May Peel)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be `'Mrs.'`. Note: Make sure that the funtion returns a string and not a list. Please modify the above function accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_title('Simonius-Blumer, Col. Oberst Alfons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be `'Col.'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named Title and extract titles from the Name column using the above function `get_title`. Hint: Use built-in [`map()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html) function. The syntax is `df['New_column'] = df['Relevant_column'].map(function_name)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us peek into the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the unique values for the titles along with their frequency. Hint: Use an inbuilt pandas function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to replace the various spellings of the same title to a single one. Hint: Use the below dictionary with the [`replace`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.replace.html) function\n",
    "\n",
    "`title_dictionary = {'Ms.': 'Miss.', 'Mlle.': 'Miss.', \n",
    "              'Dr.': 'Rare', 'Mme.': 'Mr.', \n",
    "              'Major.': 'Rare', 'Lady.': 'Rare', \n",
    "              'Sir.': 'Rare', 'Col.': 'Rare', \n",
    "              'Capt.': 'Rare', 'Countess.': 'Rare', \n",
    "              'Jonkheer.': 'Rare', 'Dona.': 'Rare', \n",
    "              'Don.': 'Rare', 'Rev.': 'Rare'}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the unique values for the titles along with their frequency to check that the titles are replaced properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the median age of passengers? Hint: Use the inbuilt function [`median`](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.median.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the median age of passengers with the title 'Miss.'? Hint: Use [`loc[]`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html) method for slicing off the select rows and the *Age* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the median age of passengers with the title 'Mrs.'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a noticeble difference in the median ages for the passengers with the above two titles? Should we take titles into account while filling the missing values for the *Age* column? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of the exercise session and the following code is part of the guided session. If you finished this and the above section earlier than the alloted time, please skip the following two sections for now to go directly to the [section 7](#section7) on merging dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. [GroupBy object](https://pandas.pydata.org/pandas-docs/version/0.22/groupby.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have created a new column *Title* that is derived from the column *Name* using regular expressions. As we saw earlier, the column *Age* has a lot of missing values. It can be filled with the median (or mean) age of all passengers, but we can also make use of the newly derived *Title* column to fill the age based on the title of the passenger. For this, it would be helpful to group the passengers based on their title to get the median age for each group and then fill the missing age values for passengers with the median age for their title.\n",
    "\n",
    "We can use [`groupby()`](https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.groupby.html) to group the rows of the dataframe based on a column(s), say *Title*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting object is not a dataframe but there are multiple ways to derive a dataframe from the grouped object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the ways to derive a dataframe from a groupby object is by aggregation, that is computing a summary statistic (or statistics) about each group. For example, we can get the median values for the columns in each group of titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Title').median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median age vary greatly for each group ranging from 3.5 to 48 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Title').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common way to derive a dataframe from a groupby object is by transformation. We create a new column *MedianAge* which consists of the groupwise median age depending on the passengers' title using [`transform()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.transform.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MedianAge'] = df.groupby('Title')['Age'].transform(\"median\")\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fill in the missing values in the *Age* column using the values in the *MedianAge* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].fillna(df['MedianAge'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check again for the missing values to see if the *Age* values are indeed filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in the Age column!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Encoding categorical variables\n",
    "\n",
    "Let us check the datatype of each column. Hint: Use [`dtypes`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dtypes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the gender values to numerical values 0 and 1 using [`replace`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.replace.html) with a suitable dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({'male': 0, 'female': 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can go wrong with randomly assigning numbers to categories?\n",
    "\n",
    "There are two kinds of categorical variables - ordinal and inordinal based on whether the categories possess an inherent order or not.\n",
    "\n",
    "For example, passengers' ticket class `Pclass` is ordinal whereas gender is inordinal.\n",
    "\n",
    "Numbers have a natural order and so do ordinal categories. Number also possess certain other characteristics that ordinal categories do not. For example, the difference between the numbers 1 and 2 is the same as the difference between the numbers 2 and 3 but the same cannot be said for ordinal categories. \n",
    "$$ 2-1 == 3-2$$\n",
    "So, converting categories to numbers means adding untrue assumptions that may or may not adversely affect our model. \n",
    "\n",
    "For this reason, the prefered method is one-hot encoding. In this method, we build a one-hot encoded vector with dimension equal to the number of classes in the categories. This vector consists of all 0's except for a 1 corresponding to the class of the instance. For example, the *Embarked* column will have one-hot encoded vectors of [1,0,0], [0,1,0] and [0,0,1] for the three ports. This means that we will have three columns for the *Embarked* columns - one for each port and the values for these columns would simply be 1 or 0.\n",
    "\n",
    "One-hot encoding is accomplished in pandas using [`get_dummies`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) as given below. It simply creates a column for each class of a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df['Embarked']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the column names to be `'Port_C', 'Port_Q', 'Port_S'`. Make use of the [`prefix` ](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) keyword in `get_dummies` to alter the column names and save the one-hot encoded vectors to a new dataframe named `port_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat the two dataframes `df` and `port_df` using [`concat`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) and save the resulting dataframe in `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- One of the columns in the one-hot encoding obtained in the above manner is always redundant. In case of features with just two classes such as gender in our dataset, one-hot encoding is not truly useful. One of its column is same as what we obtained by simply replacing classes with 0 and 1 and the other is redundant.  \n",
    "- The main disadvantage of using one-hot encoding is the increase in the number of features that can negatively affect our model which we will discuss in the later sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Correlation between variables (Optional)\n",
    "\n",
    "What are the possible ways to understand the correlation of features with survival? Does correlation always implies causation?\n",
    "\n",
    "Pearson correlation coefficients measures the linear correlation between the variables.\n",
    "\n",
    "$$\\rho_{X,Y} = \\frac{cov(X, Y)}{\\sigma_X, \\sigma_Y}$$\n",
    "where \n",
    "- $cov(X, Y)$ is the covariance.    \n",
    "- $\\sigma_X, \\sigma_Y$ are standard deviations of $X$ and $Y$ respectively.\n",
    "\n",
    "The correlation between two variables ranges from -1 to 1. The closer in absolute value a correlation is to 1, the more dependent two features are each other.\n",
    "\n",
    "We can get the correlation matrix for the variables (columns) in the dataset using the built-in function `corr()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From the above matrix, note which feature has the highest correlation with the survival. \n",
    "* Do features have high correlation among themselves? \n",
    "* Note that this matrix has excluded some categorical variables like gender, port of embarkment, etc. \n",
    "\n",
    "The correlation matrix can also be visualized using heatmaps as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr();\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(correlation_matrix);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Merging columns from different datasets (Optional) <a name=\"section7\"></a>:\n",
    "A simple illustration to merge two datasets using [`merge()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'CourseCode': ['PHYS024', 'CSCI35', 'ENGR156'], \n",
    "                   'CourseName': ['Mechanics and Wave Motion', \n",
    "                                  'Computer Science for Insight',\n",
    "                                 'Intro to Comm & Info Theory']})\n",
    "\n",
    "df2 = pd.DataFrame({'Professor': ['Zachary Dodds', 'Vatche Sahakian', \n",
    "                                  'Timothy Tsai', 'Brian Shuve'],\n",
    "                    'CourseCode': ['CSCI35', 'PHYS024',  'ENGR156', 'PHYS024']})\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df2, df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to the documents [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) and [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) to better grasp how and when to use `merge()` function. \n",
    "\n",
    "#### Merging dataframes from [Instacart Market Basket Analysis](https://www.kaggle.com/c/instacart-market-basket-analysis/data) dataset:\n",
    "We load the four files into separate dataframes:   \n",
    "`aisles.csv`   \n",
    "`departments.csv`  \n",
    "`products.csv`  \n",
    "`order_products__train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'instacart-market-basket-analysis/'\n",
    "dfa = pd.read_csv(path + 'aisles.csv')\n",
    "dfd = pd.read_csv(path + 'departments.csv')\n",
    "dfp = pd.read_csv(path + 'products.csv')\n",
    "dfo = pd.read_csv(path + 'order_products__train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Familiarize yourself with the dataframes. Hint: Use [`head()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html).  \n",
    "Note: You might want to add code cells. Please ask for help unless you already know how to add a code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal: Get a dataframe consisting of the name of the products along with their aisle names and department names for the order with `order_id` equal to 1.**  \n",
    "This dataframe must have ***8 rows and only three columns:\n",
    "```'product_name', 'aisle', 'department'```***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First slice out 8 rows from the order_products dataframe that corresponds with `order_id` equal to 1 and save it in a new dataframe `df`. Hint: Use conditional on indexing as seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a peek into the dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe `df` has a column named `product_id`. So, we can merge it with the dataframe `dfp` to get `product_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the dataframes `df` and `dfp` using [`merge()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) and save the result back to `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check whether the new columns are added to the dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have new columns `aisle_id` and `department_id`. Let us first merge `dfa` with this dataframe to get the column `aisle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check our dataframe `df` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it should have the column `aisle`. Let us now merge `dfd` with this dataframe to get the column `department`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check our dataframe `df` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we only select 3 columns: `'product_name', 'aisle', 'department'`. Hint: Use indexing with the list of columns as seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also check the shape of the dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be `(8, 3)`. Please check your code above if you get something else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Feature engineering on the Titanic dataset to create a new column for group size (Optional home work exercise)\n",
    "\n",
    "In this exercise, we are going to create a new column called `GroupSize` to get the size of the group for each passenger. We consider groups to be either family members or those traveling on the same ticket. This feature is derived using three columns *SibSp*, *Parch* and *Ticket*. \n",
    "\n",
    "[Notes](https://www.kaggle.com/c/titanic/data) for the two features *SibSp* and *Parch* are as follows.\n",
    "\n",
    "> SibSp: The dataset defines family relations in this way...  \n",
    "Sibling = brother, sister, stepbrother, stepsister  \n",
    "Spouse = husband, wife (mistresses and fiancÃ©s were ignored)\n",
    "> \n",
    "> Parch: The dataset defines family relations in this way...  \n",
    "Parent = mother, father  \n",
    "Child = daughter, son, stepdaughter, stepson  \n",
    "Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "\n",
    "Create a new column named *Family* by adding the columns *SibSp* and *Parch* and then add 1 to it. Hint: Use `df[\"New_column\"] = df[\"column_1\"] + df[\"column_2\"] + 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check the survival rates with respect to the family size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Family', y='Survived', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some passengers that appear to be traveling alone by account of their family size were part of a group traveling on the same ticket. To see this, get all the passengers traveling on the ticket \"1601\" (there are 7 of them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can check that there are many tickets shared among passengers that may or may not be family members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ticket'].value_counts()[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named *TicketCount* that counts the total number of passengers traveling in each passengers' ticket.\n",
    "\n",
    "Hint: \n",
    "- First group passengers based on their tickets using `groupby()` on the *Ticket* column.\n",
    "- For the grouped object, pick any column that has no missing values.\n",
    "- Use `transform()` for this unique identifier column with the function `\"count\"` to create a new column *TicketCount*.\n",
    "\n",
    "For example, we created *MedianAge* using the following code:   \n",
    "```df['MedianAge'] = df.groupby('Title')['Age'].transform(\"median\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us peek into the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the survival rates based on the *TicketCount* using [`sns.barplot()`](https://seaborn.pydata.org/generated/seaborn.barplot.html) (see above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does seem that the number of co-travelers have an impact on the survival rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named *GroupSize* by picking the maximum value among the columns *Family* and *TicketCount*.   \n",
    "Note: We consider groups to be either family members or those traveling on the same ticket.   \n",
    "Hint: Use built-in `max()` function for pandas on the two relevant columns with the appropriate value for the `axis` parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the survival rates based on the GroupSize using sns.barplot()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of rows where Groupsize is not equal to Family. Similarly, check the number of rows where TicketCount is not equal to Family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['GroupSize'] != df['Family']].shape[0], df[df['GroupSize'] != df['TicketCount']].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output must be `(97, 191)`. Check your above code, if you get a different output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acknowledgment:\n",
    "* [Titanic dataset from Kaggle](https://www.kaggle.com/c/titanic) dataset openly available in Kaggle is used in the exercises.\n",
    "\n",
    "**Note:**\n",
    "The solutions for this exercise can be found [here]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
